\documentclass[12pt,a4paper,titlepage]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage[T1]{fontenc}
\usepackage[pdftex]{color,graphicx}
\usepackage{listings}
\usepackage{url}
\usepackage{titlesec}
\usepackage{tabularx}
\usepackage[hidelinks]{hyperref}

\titleclass{\subsubsubsection}{straight}[\subsection]

\newcounter{subsubsubsection}
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\renewcommand\theparagraph{\thesubsubsubsection.\arabic{paragraph}} % optional; useful if paragraphs are to be numbered

\titleformat{\subsubsubsection}
  {\normalfont\normalsize\bfseries}{\thesubsubsubsection}{1em}{}
\titlespacing*{\subsubsubsection}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{5}{\z@}%
  {3.25ex \@plus1ex \@minus.2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\renewcommand\subparagraph{\@startsection{subparagraph}{6}{\parindent}%
  {3.25ex \@plus1ex \@minus .2ex}%
  {-1em}%
  {\normalfont\normalsize\bfseries}}
\def\toclevel@subsubsubsection{4}
\def\toclevel@paragraph{5}
\def\toclevel@paragraph{6}
\def\l@subsubsubsection{\@dottedtocline{4}{7em}{4em}}
\def\l@paragraph{\@dottedtocline{5}{10em}{5em}}
\def\l@subparagraph{\@dottedtocline{6}{14em}{6em}}
\makeatother

\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

\definecolor{gray}{RGB}{127,127,127}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

% Espacio entre párrafos
\setlength{\parskip}{0.2\baselineskip}

\lstset{
basicstyle=\ttfamily,                   	% Code font
stepnumber=1,                           	% Step between two line-numbers
numbersep=5pt,                          	% How far are line-numbers from code
frame=topbottom,                             	% A frame around the code
tabsize=4,                              	% Default tab size
captionpos=b,                           	% Caption-position = bottom
breaklines=true,                        	% Automatic line breaking?
breakatwhitespace=false,                	% Automatic breaks only at whitespace?
showspaces=false,                       	% Dont make spaces visible
showtabs=false,                         	% Dont make tabls visible
linewidth=\textwidth,                   	% Defines the base line width
}

\author{
	Daniel Garabato Míguez
	\and Vanesa López Beade
	\and Daniel Valcarce Silva
}
\title{Memoria Práctica LN}
\date{Curso 2012-2013}

\begin{document}

% Título
\begin{titlepage}
\begin{center}
\includegraphics[width=10cm]{res/logo_udc}\\
\vspace{1cm}
\textsc{\Large Lenguajes Naturales}\\[0.5cm]
\textsc{\Large Curso 2012/2013}\\[0.5cm]

\HRule \\[0.4cm]
{ \huge \bfseries My Little Trivial Player}\\[0.4cm]
{ \Large \bfseries Memoria de la Práctica}\\[0cm]

\HRule \\[0cm]
\end{center}

\vfill
\emph{Autores:}
\vspace{0.5cm}
\\
\vspace{0.1cm}
Garabato Míguez, Daniel \texttt{<daniel.garabato@udc.es>}\\
\vspace{0.1cm}
López Beade, Vanesa \texttt{<vanesa.lopezb@udc.es>}\\
\vspace{0.1cm}
Valcarce Silva, Daniel \texttt{<daniel.valcarce@udc.es>} (Portavoz)\\

\end{titlepage}


% Índice
\tableofcontents
\clearpage

%Cuerpo
\section{Introducción}
El objetivo de la presente práctica es realizar la implementación de un sistema de búsqueda de respuestas (\emph{question answering}). Para ello, en primer lugar, diseñaremos una arquitectura general del sistema en la que se especificará el objetivo de cada uno de los módulos.

Para implementar las distintas unidades funcionales de la práctica, implementaremos nuestros propios algoritmos, pero también haremos uso de múltiples herramientas de terceros. Describiremos dichas herramientas y para qué las hemos utilizado.

Consideraremos diferentes estrategias a la hora de resolver las diferentes problemáticas. Implementaremos aquellas que estén a nuestro alcance y las evaluaremos para quedarnos con las que nos den mejores resultados.

Se incluye en esta memoria un manual de instalación de la aplicación puesto que al hacer uso de múltiples herramientas de diferentes tecnologías es necesario la instalación de numerosos paquetes. Por otro lado, la memoria también contiene unas instrucciones de uso de la práctica.

\clearpage
\section{Arquitectura del sistema}
Basándonos en varios modelos conceptuales de un sistema de búsqueda de respuestas \cite{modelo1}, \cite{modelo2} y el dado en la asignatura, hemos desarrollado nuestra propia arquitectura que puede verse en la Figura \ref{fig:arquitectura}.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=0.9\textwidth]{res/arquitectura}
\end{center}
\caption{Arquitectura general del sistema}
\label{fig:arquitectura}
\end{figure}

\begin{description}
	\item[Query Formulation] A partir de una pregunta en lenguaje natural genera una consulta (\emph{query}) que será posteriormente interpretada por un motor de búsqueda web.
	\item[Document Retrieval] Obtiene una lista de documentos tras realizar la consulta pertinente en los motores de búsqueda.
	\item[Passage Retrieval] Devuelve los pasajes relevantes de la lista de documentos anterior.
		\begin{description}
			\item[Document Segmentation] Divide cada documento en pasajes.
			\item[Passage Filtering] Selecciona los pasajes más relevantes.
		\end{description}
	\item[Answer Procesing] Genera las respuestas asociadas a los pasajes relevantes.
		\begin{description}
			\item[Answer Extraction] Extrae las respuestas asociadas a cada pasaje.
			\item[Answer Filtering]	Filtra las mejores respuestas.
		\end{description}
\end{description}

\subsection{Vista estática}
Con el objetivo de representar los distintos elementos que dan soporte a nuestro sistema se ha elaborado un diagrama de clases que puede observarse en la Figura \ref{fig:clases}.

En la vista estática se representan las clases que se desarrollarán para implementar las funcionalidades requeridas de la misma y sus propiedades, tanto sus atributos y métodos como sus relaciones con otras clases del dominio. Además, se muestra también la conexión entre los elementos propios que hemos desarrollado y los módulos o paquetes de terceros que se han utilizado.

\begin{figure}[h!]
\begin{center}
\includegraphics[angle=90,width=0.85\textwidth]{res/clases}
\end{center}
\caption{Diagrama de clases de la práctica}
\label{fig:clases}
\end{figure}

\subsection{Vista dinámica}
Para ilustrar el proceso de búsqueda de respuestas del sistema, hemos elaborado un diagrama de secuencia que puede verse en la Figura \ref{fig:secuencia}. En dicho diagrama se puede observar el flujo del programa durante la búsqueda de respuestas ante una pregunta realizada por el usuario por línea de comandos.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=\textwidth]{res/secuencia}
\end{center}
\caption{Diagrama de secuencia del proceso de búsqueda de respuestas}
\label{fig:secuencia}
\end{figure}

\clearpage
\section{Herramientas empleadas}
Durante el desarrollo de la práctica se emplearon diversas utilidades de terceros que han permitido facilitar el desarrollo de la misma y simplificar, parcialmente, su complejidad mediante la incorporación de módulos ya desarrollados que posibilitan su elaboración, puesto que sin ellos el alcance de la implementación sería inabordable. A continuación se especifican cuales son las herramientas principales en las que nos hemos basado.

\begin{description}
	\item[NLTK] Se trata de una plataforma libre para el desarrollo de aplicaciones en lenguaje Python que permite llevar a cabo un procesamiento del lenguaje natural.

\emph{NLTK} proporciona interfaces para tratar con múltiples \emph{corpus} y diversos recursos léxicos, como por ejemplo \emph{WordNet}, que permiten llevar a cabo su propósito de tratar el lenguaje natural permitiendo funcionalidades como la realización de análisis sintácticos, tokenización o la clasificación de textos, que han sido algunos de los pilares fundamentales sobre los cuales se ha construído nuestra práctica.

Puede obtenerse más información a cerca del mismo, así como descargarse, en \cite{nltk}.

	\item[Pattern] Consiste en un módulo libre de \emph{web mining} para Python. Su principal funcionalidad es la extracción de información mediante la realización de consultas a diversos búscadores web como \emph{Google}, \emph{Bing} o \emph{Wikipedia}.

La utilización de este módulo nos ha permitido manejar las API's de los diferentes buscadores a través de la interfaz que proporciona el propio módulo, logrando encapsular el funcionamiento y las particularidades de cada API.

Se puede encontrar más información en \cite{pattern}.

	\item[PDFMiner] Módulo de Python que permite llevar a cabo la conversión de un documento en formato PDF a texto plano. Esta herramienta nos ha facilitado el tratamiento de los documentos PDF recuperados de la web, ya que, por su propia naturaleza, contienen información adiccional que es irrelevante para nuestro propósito y que, a través de esta utilidad, conseguimos obviar.

Se puede obtener más información en \cite{pdfminer}.

	\item[lxml] Consiste en un módulo que posibilita el manejo de datos estructurados en XML y HTML a través de una sencilla interfaz en Python. Puede encontrarse más información sobre el mismo en \cite{lxml}.

	\item[Stanford NER] También conocido como \emph{CRFClassifier}, se trata de un reconocedor de entidades implementado en Java que permite clasificar las diferentes entidades de un texto según su dominio: nombres, organizaciones, lugares, etc.

Su funcionamiento a través de \emph{sockets} nos ha permitido incorporarlo a nuestra implementación de la práctica. Puede obtenerse más información sobre esta herramienta en \cite{stanford-ner}.

	\item[Stanford Parser] Se trata de un analizador de lenguaje natural que permite, mediante una etiquetación, identificar los diferentes elementos que componen un texto: frases, sujeto, verbo, etc.

	Del mismo modo que el \emph{Stanford NER} se comunica a través de \emph{sockets} con nuestro programa en Python. Se puede encontrar más información sobre el mismo en \cite{stanford-parser}.

	\item[WordNet] Consiste en una base de datos léxica en Inglés capaz de agrupar las palabras conjuntos de sinónimos (\emph{synsets}) y de almacenar las relaciones semánticas entre dichos conjuntos. Además también puede proporcionar breves definiciones de carácter general.

	Puede encontrarse más información en \cite{wordnet}.

	\item[Git] Sistema de control de versiones distribuido que facilita las tareas de desarrollo del software proporcionando soporte a diferentes versiones del mismo. Puede obtenerse más información en \cite{git}.

	\item[BitBucket] Utilidad online que permite la creación de repositorios centralizados para sistemas de control de versiones como \emph{git} o \emph{mercurial}. Puede accederse a nuestro repositorio en \cite{bitbucket}.

	\item[\LaTeX] Sistema de composición de textos con el que se ha elborado el presente documento. Más información en \cite{latex}.

\end{description}


\clearpage
\section{Manual de instalación y uso}
En esta sección se describen los pasos a seguir para instalar correctamente todos los componentes necesarios para ejecutar nuestra práctica. Asimismo, también se adjuntan las intrucciones detalladas de uso.

A pesar de que las tecnologías utilizadas son multiplataforma, se recomienda utilizar un sistema operativo UNIX. Concretamente, se ha comprobado el correcto funcionamiento de la práctica en ArchLinux 2012.10.06, Debian 7.0, Mac OS X 10.8 y Ubuntu 11.04.

\subsection{Instalación del sistema}
A continuación se detallan los paquetes necesarios y cómo instalarlos.

\subsubsection{Python y sus módulos}
Es necesario disponer de una versión moderna de Python 2 (al menos Python 2.6, pero se recomienda Python 2.7). En el sitio web de Python se puede descargar el intérprete \cite{python}. Hemos utilizado únicamente el intérprete recomendado (CPython) con lo que no podemos garantizar el correcto funcionamiento en otras implementaciones como PyPy.

Una vez obtenido Python, es necesario instalar diversos módulos. Para simplificar el proceso, es preciso disponer de las SetupTools de Python. Hay scripts disponibles para diversas plataformas que pueden descargarse de su sitio web \cite{setuptools}.

\begin{lstlisting}
# sh path/to/downloads/setuptools-{version}.egg
\end{lstlisting}

Es preciso instalar Pip para instalar el resto de módulos:

\begin{lstlisting}
# easy_install pip
\end{lstlisting}

A continuación, instalamos los módulos Numpy, PyYAML, NLTK, PDFMiner, lxml y Pattern con Pip:

\begin{lstlisting}
# pip install -U numpy pyyaml nltk pdfminer lxml pattern
\end{lstlisting}

Es necesario bajarse los corpus del NLTK para que funcionen correctamente algunas de sus características como el PoS Tagger o el Named Entity Recognition Tagger:

\begin{lstlisting}
$ python
>>> import nltk
>>> nltk.download('all')
\end{lstlisting}


\subsubsection{Java}
Aunque nuestra práctica está realizada en Python, utilizamos herramientas del grupo Stanford NLP que están desarrolladas en Java. Estas requieren Java 6 o superior. En la web de Oracle se puede descargar el JDK \cite{java}.

Los componentes de Stanford que se son necesarios ya vienen incluidos con el código de la práctica por lo que no es necesario descargarse nada más.

\subsubsection{Claves de buscadores}
El módulo de obtención de documentos de la web requiere unas \emph{API Keys} de los buscadores a utilizar. En el fichero de configuración de la práctica ya se incluye por defecto unas claves gratuitas de Google y Bing que pueden ser sustituidas por otras claves válidas sin dificultad.

La clave de Google permite realizar 100 consultas por hora, mientras que la de Bing da acceso a 5000 consultas al mes.


\subsection{Uso del sistema}
El sistema tiene dos modos de funcionamiento principales así como un tercero con objetivos de \emph{debugging}. Con el objetivo de facilitar el uso de nuestro programa, se ha codificado un script en Bash (\texttt{launch.sh}) localizado en la carpeta \texttt{src} del proyecto que permite lanzar fácilmente la práctica.

En cualquiera de los tres modos de ejecución, las respuestas se almacenan en un fichero en la carpeta \texttt{res}. El nombre de dicho fichero se obtiene a partir del \emph{timestamp} de la hora de ejecución del programa.

\subsubsection{Modo interactivo}
El modo interactivo permite al usuario introducir una pregunta por la entrada estándar. El sistema buscará procesará la pregunta y devolverá la respuesta en el fichero de respuestas.

Para iniciar este modo, debemos ejecutar el script con la opción \emph{interactive}:
\begin{lstlisting}
$ ./launch.sh interactive
\end{lstlisting}

O bien ejecutar directamente el código Python:
\begin{lstlisting}
$ python QA.py
\end{lstlisting}

\subsubsection{Modo \emph{batch}}
Para el procesamiento de preguntas por lotes, nuestra práctica permite especificar un fichero en el que se leerán una serie de preguntas que serán procesadas secuencialmente. Los resultados de cada pregunta se encuentran todos en el mismo fichero.

El formato del fichero de preguntas es el siguiente. Cada pregunta se encontrarán en una línea y estará precedida por un código alfanumérico (sin blancos). A continuación de dicho código, el resto de la línea será considerado el cuerpo de la pregunta.

Este modo de ejecución puede ser invocado desde el script con la opción \emph{batch} seguido de la ruta del fichero de preguntas:
\emph{interactive}:
\begin{lstlisting}
$ ./launch.sh batch <file>
\end{lstlisting}

También se puede ejecutar directamente el código Python:
\begin{lstlisting}
$ python QA.py <file>
\end{lstlisting}

\subsubsection{Modo \emph{debug}}
Por último, nuestra práctica permite ejecutar el proceso de búsqueda de respuestas a partir de un conjunto de documentos ya obtenidos de los motores de búsqueda. El objetivo de esta modalidad de ejecución es limitar el número de consultas web durante la fase de pruebas debido a los límites de las claves gratuitas de Bing y Google.

Para que funcione correctamente este módulo, es necesario realizar en primer lugar una pregunta de modo interactivo o \emph{batch} con la opción \emph{persistence.document} activada en el fichero de configuracion (más información sobre cómo modificar la configuración de la práctica en la Sección \ref{section:conf}). Esto nos generará un fichero llamado \texttt{documentos.pkl} que contiene los documentos obtenidos serializados mediante el módulo Pickle de Python y que es necesario para la ejecución en modo \emph{debug}.

A continuación, solo se necesita ejecutar el script la opción \emph{debug}:
\begin{lstlisting}
$ ./launch.sh debug
\end{lstlisting}

Alternativamente, se puede ejecutar directamente el código Python:
\begin{lstlisting}
$ python QA.py pickle
\end{lstlisting}

\subsection{Fichero de configuración}
\label{section:conf}
Para dotar de mayor flexibilidad a la práctica, se han creado dos ficheros de configuración que permiten modificar el comportamiento de los diversos módulos y del sistema de \emph{logging}.

\subsubsection{\texttt{src/conf/config.conf}}
Permite modificar los parámetros de los diversos módulos del sistema de búsqueda de repuestas. Las posibles opciones se encuentran en forma de comentario dentro del fichero de configuración y tienen nombres autodescriptivos.

\subsubsection{\texttt{src/conf/logging.conf}}
El fichero de configuración del módulo Logging de Python permite establecer qué tipo de \emph{logs} se registran en ficheros de texto o por salida estándar. Para más información, consultar la referencia oficial del módulo \cite{logging}.

\clearpage
\section{Algoritmos}
En esta sección se detallan los algoritmos utilizados en el sistema de búsqueda de respuestas.

\subsection{Query Formulation}
El objetivo de estos algoritmos es formular una consulta para los buscadores web a partir de la pregunta introducida por el usuario.

\subsubsection{Stopwords}
Este algoritmo nos devuelve una query. Es llamado cada vez que se crea un objeto de tipo Question y recibe el texto de la pregunta. Su funcionamiento consiste en primero pasar el texto de la pregunta a minúsculas y , a continuación, obtenemos una lista con los caracteres de la pregunta. De esta lista eliminamos los símbolos que no nos interesan (comas, interrogaciones, exclamaciones, etc.) puesto que no nos influyen en la búsqueda. Tenemos así el texto de la pregunta filtrado.

Finalmente obtenemos otra lista con las palabras de la pregunta y, utilizando el corpus del NLTK con las \emph{stopwords}, eliminamos las palabras irrelevantes a la hora de realizar la búsqueda. Tenemos así nuestra query lista para pasársela a los buscadores.

\subsection{Document Segmentation}
Los siguientes algoritmos son llamados cada vez que se crea un objeto de tipo Documento; les pasaremos un documento y nos devolverán la lista de pasajes de dicho documento.

\subsubsection{Split into Lines}
En este primer algoritmo obtenemos pasajes compuestos por un número fijo de líneas ( a determinar por el usuario, en caso de fallo al obtenerlo, dicho número será 5 ) del documento superponiendo dichos pasajes. Para ello, se divide el contenido del documento en líneas y se itera sobre estas líneas de manera que cada pasaje estará formado por el número de líneas fijado. En cada nueva iteración, un pasaje estará formado por dicho número de líneas menos una del pasaje de la iteración anterior más una nueva línea. Por último se añade también como pasaje la descripción que nos ofrece el motor de búsqueda ya que puede resultar relevante según la lógica del buscador.

\subsubsection{Split into Paragraphs}
En este segundo caso, la forma de obtener pasajes cambia para obtener en cada pasaje un único párrafo. Se divide el contenido del documento en líneas y cada pasaje estará formado por una de ellas. Añadiendo además, como en el caso anterior, el pasaje formado por la descripción ofrecida por el motor de búsqueda.

\subsubsection{Split into Sentences}
Por último, este algoritmo obtiene pasajes formados por el número de frases indicadas por el usuario. El contenido del documento se divide en frases utilizando el sent\_tokenize del NLTK. Se añade además, como en los dos casos anteriores, el pasaje formado por la descripción ofrecida por el motor de búsqueda.

\subsection{Passage Filtering}
Estos algoritmos fijarán una determinada puntuación a cada pasaje según su relevancia para una determinada pregunta para así poder seleccionar los mejores.

\subsubsection{Similarity}
En primer lugar, al texto de la pregunta y del pasaje les eliminamos las stopwords con el algoritmo de Query Formulation: Stopwords y dividimos ambos textos en palabras, obteniendo dos listas. A continuación, aplicamos stemming sobre ambas listas, obtenemos las palabras que están en ambas listas y este número de palabras coincidentes será nuestra puntuación inicial.

Por último, los pasajes que pertenezcan a documentos obtenidos de respuestas situadas en las posiciones más altas del ranking de respuestas devueltas por los motores de búsqueda obtendrán mayor puntuación por considerarse que esto indica que son mejores. Normalizamos el ranking del documento al que pertenece el pasaje que estamos puntuando y multiplicamos la puntuación inicial anterior por esta cantidad, obteniendo así, la puntuación final del pasaje.

\subsubsection{Proximity}
Como en el caso del algoritmo anterior primero eliminamos las stopwords con el algoritmo de Query Formulation: Stopwords, dividimos ambos textos en palabras y aplicamos stemming tanto sobre la lista de palabras de la pregunta como la de palabras del pasaje.

A la hora de puntuar los pasajes se valora que estos tengan palabras de la pregunta cercanas entre si, asignándole una puntuación de acuerdo a lo próximas que estén entre sí.

\subsubsection{Mixed}
Consideramos en este algoritmo una estrategia mixta, asignándole a cada pasaje la media de la puntuación obtenida con los dos algoritmos anteriores (Similarity y Proximity).

\subsection{Answer Extraction}
Los algoritmos de extracción de respuestas tienen como objetivo hallar una respuesta dados una pregunta y un pasaje relevante.

\subsubsection{Entity Recognition}
\label{s:ne_recog}
El funcionamiento de este algoritmo se basa en la extracción de entidades del texto de un pasaje. Para ello, en primer lugar, obtenemos la clasificación de la pregunta y, a continuación, recuperamos las entidades adecuadas a dicha clasificación.

Para cada pasaje, devolvemos la entidad que más se repite en la pregunta con una puntuación que determina su frecuencia de aparición en el pasaje.

\subsubsubsection{Question Classification}
Realizamos una clasificación de la pregunta para saber qué tipo de entidades debemos obtener del pasaje. Para ello hemos entrenado diferentes clasificadores a partir de un corpus de entrenamiento formado por preguntas y su clasificación en Other, Number, Person, Location, Time, Date, Money, Percent y Organization.

Hemos utilizado tres tipos de clasificadores: de Bayes ingenuo, de árbol de decisión y de máxima entropía. A su vez, hemos utilizado diferente combinaciones de las siguientes características: primera palabra (o dos primeras si empieza por preposición), primer sustantivo y \emph{head word}.

Para obtener la \emph{head word}, es decir, la palabra clave que indica el tipo de pregunta hemos utilizado el algoritmo descrito en \cite{tesis:qc} y \cite{paper:qc}.

Tras probar todas las combinaciones posibles de clasificadores y características, el que mejor resultados da en el conjunto de test ha sido el clasificador bayesiano ingenuo con la \emph{head word} y la primera palabra.

\subsubsubsection{Named Entity Recognition}
Una vez obtenida la clasificación de la pregunta, debemos buscar las entidades de ese tipo. Para ello, utilizamos el NER Parser de Stanford que permite la extracción de entidades tipo Time, Location, Organization, Person, Money, Percent y Date; sin embargo, debemos definir estrategias diferentes para los Number y los Other.

Descartamos aquellas respuestas que son palabras que ya aparecen en la pregunta.

También es posible emplear el extractor de entidades del NLTK (se puede indicar en el fichero de configuración); no obstante, hemos visto que proporciona peores resultados.

\subsubsubsection{Number Recognition}
Para reconocer entidades Number utizamos el Part-of-Speech Tagger del NLTK obteniendo los numerales cardinales y ordinales (CD y JJ) y una expresión regular que reconoce caracteres numéricos.

\subsubsubsection{Other Recognition}
Por último, la extracción de entidades tipo Other se realiza obteniendo los sustantivos comunes que no son entidades tras un análisis léxico por parte del NLTK. A continuación obtenemos la \emph{head word} correspondiente a la pregunta y buscamos su \emph{synset} en WordNet. Comparamos con el \emph{synset} de cada uno de los sustantivos candidatos mediante la métrica de similitud Lin \cite{wn1} \cite{wn2} \cite{wn3}. Aceptamos como posibles respuetas todos aquellos sustantivos que se encuentren entre un umbral mínimo ---así eliminamos palabras no relacionadas--- y un umbral máximo ---no queremos sinónimos de la \emph{head word}.

Si el algoritmo de obtención de \emph{head word} no es capaz de devolver un término, evaluamos todos los sustantivos como posibles respuestas (no podemos utilizar la metodología anteriormente descrita).

Si la \emph{head word} no es vacía, entonces buscamos su \emph{synset} correspodiente en WordNet. En caso de encontrarlo procedemos con normalidad. Por el contrario, si no existe entonces buscamos el \emph{synset} del primer sustantivo de la pregunta. Si aún así, no conseguimos un \emph{synset}, devolvemos todos los sustantivos; en el caso opuesto, procedemos con la métrica de similitud entre el primer sustantivo y las palabras candidatas.

\clearpage
\section{Resultados}
En las siguientes tablas se muestran los resultados obtenidos para las pruebas realizadas. Nos quedamos con la cuarta configuración puesto que es con la que obtenemos un mayor MRR aunque la quinta opción también es bastante buena.

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Id & Document Retrieval & Document Segmentation & Passage Filtering\\\hline
1 & 20 resultados & paragraphs/-/100 & mixed\\\hline
2 & 20 resultados & paragraphs/-/100 & proximity\\\hline
3 & 20 resultados & paragraphs/-/200 & similarity\\\hline
4 & 20 resultados & sentences/1/500 & mixed\\\hline
5 & 20 resultados & sentences/1/500 & proximity\\\hline
6 & 20 resultados & sentences/1/500 & similarity\\\hline
7 & 20 resultados & sentences/5/500 & mixed\\\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
Id & run-tag & MRR estricto & MRR permisivo & Respuestas R\\ \hline
1 & plnaex031ms & 0,34667 & 0,34667 & 19\\ \hline
2 & plnaex031ms & 0,27333 & 0,27333 & 16\\ \hline
3 & plnaex031ms & 0,36 & 0,36 & 19\\ \hline
4 & plnaex031ms & 0,35667 & 0,35667 & 20\\ \hline
5 & plnaex031ms & 0,34 & 0,34 & 22\\ \hline
6 & plnaex031ms & 0,33333 & 0,33333 & 20\\ \hline
7 & plnaex031ms & 0,29667 & 0,29667 & 18\\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
Id & R o U & NILs & NILs correctos & \% R & \% R o U\\ \hline
1 & 19 & 1 & 0 & 38,00\% & 38,00\% \\ \hline
2 & 16 & 3 & 0 & 32,00\% & 32,00\% \\ \hline
3 & 19 & 1 & 0 & 38,00\% & 38,00\% \\ \hline
4 & 20 & 2 & 0 & 40,00\% & 40,00\% \\ \hline
5 & 22 & 2 & 0 & 44,00\% & 44,00\% \\ \hline
6 & 20 & 2 & 0 & 40,00\% & 40,00\% \\ \hline
7 & 18 & 2 & 0 & 36,00\% & 36,00\% \\ \hline
\end{tabular}
\end{center}
\end{table}


\clearpage
\section{Bibliografía}
\renewcommand{\section}[2]{}
\begin{thebibliography}{9}

\bibitem{modelo1}
J. Lin, B. Katz: \emph{Question Answering Techniques for the World Wide Web}. EACL (2003). \url{http://www.umiacs.umd.edu/~jimmylin/publications/Lin_Katz_EACL2003_tutorial.pdf}.

\bibitem{modelo2}
B. Magnini: \emph{Open Domain Question Answering: Techniques, Resources and Systems}. RANLP (2005). \url{http://lml.bas.bg/ranlp2005/tutorials/magnini.ppt}.

\bibitem{python}
Python: \url{http://www.python.org}.

\bibitem{setuptools}
Python SetupTools: \url{http://pypi.python.org/pypi/setuptools}.

\bibitem{nltk}
NLTK: \url{http://www.nltk.org}.

\bibitem{nltk-book}
S. Bird, E. Klein, E. Loper: \emph{Natural Language Processing with Python --- Analyzing Text with the Natural Language Toolkit}, O'Reilly Media (2009).

\bibitem{pattern}
CLIPS Pattern: \url{http://www.clips.ua.ac.be/pages/pattern}.

\bibitem{pdfminer}
PDFMiner: \url{http://www.unixuser.org/~euske/python/pdfminer/index.html}.

\bibitem{lxml}
lxml: \url{http://lxml.de/}.

\bibitem{stanford-ner}
Stanford NER: \url{http://nlp.stanford.edu/software/CRF-NER.shtml}

\bibitem{stanford-parser}
Stanford Parser: \url{http://nlp.stanford.edu/software/lex-parser.shtml}

\bibitem{wordnet}
WordNet: \url{http://wordnet.princeton.edu}

\bibitem{java}
Oracle Java: \url{http://www.oracle.com/us/technologies/java/overview/index.html}.

\bibitem{git}
Git: \url{http://www.git-scm.com}.

\bibitem{bitbucket}
BitBucket: \url{http://www.bitbucket.org/daniel_garabato/ln}.

\bibitem{latex}
\LaTeX: \url{http://www.latex-project.org}.

\bibitem{logging}
Configuración del módulo Logging de Python: \url{http://docs.python.org/2/library/logging.config.html}.

\bibitem{tesis:qc}
B. Loni: \emph{Enhanced Question Classification with Optimal Combination of Features}. Ed. Delft University of Technology, 2011.

\bibitem{paper:qc}
J. Silva et al: \emph{From symbolic to sub-symbolic information in question classification}. Ed. Springer Science (2010).

\bibitem{wn1}
Martin Warin: \emph{Using WordNet and Semantic Similarity to Disambiguate an Ontology}. Ed. Institutionen för lingvistik. Stockhomls Universitet (2004).

\bibitem{wn2}
Alexander Budanitsky, Graeme Hirst: \emph{Evaluating WordNet-based Measures of Lexical Semantic Relatedness}. Ed. University of Toronto.

\bibitem{wn3}
Alexander Budanitsky, Graeme Hirst: \emph{Semantic distance in WordNet: An experimental, application-oriented evaluation of five measures}. Ed. University of Toronto.

\end{thebibliography}

\end{document}
